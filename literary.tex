%    This program is free software: you can redistribute it and/or modify
%    it under the terms of the GNU General Public License as published by
%    the Free Software Foundation, either version 3 of the License, or
%    (at your option) any later version.
%
%    This program is distributed in the hope that it will be useful,
%    but WITHOUT ANY WARRANTY; without even the implied warranty of
%    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
%    GNU General Public License for more details.
%
%    You should have received a copy of the GNU General Public License
%    along with this program.  If not, see <http://www.gnu.org/licenses/>.\documentclass[a4paper,11pt]{article}
%
%    Copyright: John A Stevenson, University of Edinburgh, Twitter: @volcan01010

\documentclass[a4paper,12pt,twocolumn]{article}

%%%%%%%%%%% PAGE SIZE: Set up page with 2 cm margins
\usepackage{anysize}
\marginsize{2cm}{2cm}{2cm}{0cm}

%%%%%%%%%%% FONTS:
\usepackage[english]{babel} 
\usepackage[T1]{fontenc} % Font encoding for Icelandic characters
\usepackage{textgreek} % Greek letters without going into Math mode
\usepackage{eulervm} % This makes mathtext upright, not italic

\usepackage[scaled]{helvet} % Helvetica.  Similar to Arial as specified by NERC
\renewcommand*{\familydefault}{\sfdefault} % Helvetica needs default font to be SansSerif
%\usepackage{libertine} % Linux Libertine font is a nice serif font
%\usepackage{lmodern} % use Latin Modern for that LaTeX look

%%%%%%%%%%% REFERENCES: 
%\usepackage[round]{natbib} % Bibliography / reference package
\usepackage{multicol} % Make reference list multicolumn

%%%%%%%%%%% FIGURES:
\usepackage{graphicx} % Includes graphics
\usepackage{float} % Allows forcing of figure locations
\usepackage{wrapfig} % Wraps text round images
% Change figure caption font
\usepackage[font=small,format=plain,labelfont=bf,up,textfont=it,up]{caption}

%%%%%%%%%%% SPACE SAVERS:
\usepackage{mdwlist} % less gaps in itemize sections
\usepackage{titlesec} % format of section titles
\titlespacing{\section}{0pt}{8pt}{4pt}
\titlespacing{\subsection}{0pt}{6pt}{2pt}
%\usepackage{setspace}
%\onehalfspacing
\linespread{0.96}

\setlength{\headheight}{0cm}
\setlength{\headsep}{0cm}
\setlength{\footskip}{0.6cm}
%\setlength{\bibsep}{0pt}
\setlength{\parskip}{0.5\parskip}
\setlength{\textfloatsep}{0.5\textfloatsep}

%%%%%%%%%%% OTHER:
\usepackage{hyperref} % Hyperlinks in pdf (remove 'hidelinks' to display)
\usepackage[dvipscolors]{xcolor}

% Gantt chart package
\usepackage{pgfgantt}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
\usepackage[modulo]{lineno}

\title{Towards literary engineering: algorithm and tools for
  evaluating, enhancing and outright producing literary works}
\author{J. J. Merelo}
\date{\today}

\begin{document}
\twocolumn[
  \begin{@twocolumnfalse}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\maketitle

\smallskip
\hrule height 1pt 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Outline}
\begin{quote}
  This project proposes the construction of a methodology and
  set of tools that aim to assess the quality, identify authors and,
  eventually, use those measures for the improvement of written texts
  (including hypertext), bringing the era of computer-aided
  copy-editing and literature in the same way computer-aided drawing
  has helped, and continues to help, art as well as engineering.
\end{quote}
\rule{\textwidth}{1pt}
\end{@twocolumnfalse}
]
\section{Introduction}

The editorial industry is in turmoil since the extensive consumption
of ebooks and the creation of self-publishing platforms such as Kindle
Direct Publishing, iTunes and Lulu. These platforms imply that many more actors are accessing the market, but at the same time, due to low profit levels, it is complicated or even impossible to live professionally off it, since hundreds of daily sales are needed for even a minimum wage.

At the same time, the quality of these works is variable. The
publishing industry has many tools: correctors, editors, career
managers and translators that are not available to single, independent
authors, or are at a high cost. These {\em literary tools} are mainly manual and have not been
automated beyond grammar and spelling corrections. The product of translation tools,
at the same time, has eventually to be reviewed by a human to reach a
good level of quality.

From the point of view of textual authors, they are at the same level
graphic designers where 20 years ago, animation artists were 80 years ago and comic book writers were 50
years ago. Or architects were a hundred years ago. Most art (or, in
contemporary terms, content creation) uses tools to automate part of
the work. Architects (physical and software) reuse patterns to build;
comic writers, for a long time, have used patterns and textures that
can be transferred to the page and they, along with graphic
illustrators, have used freehand software tools to perform all kind of
tasks, from simple fills to more complex transitions. Animation artist
work on models, and, instead of painstakingly moving physical models
of their characterss  Harryhausen-style create models which are then
used in complex software pipelines to create motion and, eventually,
the whole motion picture.

However, writers, barring plagiarism, do have to sit down to write,
letter by letter and sentence by sentence, their whole work, and this
affects creative as well as commercial writers. The most advanced tool
that they use is a typo and grammar checker, but even so the draft has
to go through several human eyes and minds to be corrected, polished
at several levels (is this character necessary? Is this final coherent
and genre-caononical?)

This project is the first step in the creation of methodologies, algorithms and
software tools that aid in automation of the whole literary creation and
copyediting process: from idea to final typesetting, and even improvement in new editions
based on the automatic processing of literary reviews or any other
kind of feedback received by the text.

This project will match natural language processing tools for
analyzing original works as well as reviews, ontologies and thesaurus
to improve the quality of written text based on several metrics: similarity to
text-mined classic works and diversity and {\em style} parameters
assigned automatically to the work, and eventually improvement of the
manuscript using metaheuristics such as evolutionary algorithms or
simulated annealing. In the case of published text, {\em quality}
assessment can include metrics that depend on the perceived fitness of
the text, including reviews and, in the case of description of
products, sales.

The project involves the creation of new algorithms for text
improvement, sentiment analysis to gauge the reaction to a particular
work mining social networks and review sites, and automatic quality
evaluation based on text mining, as well as development of open-source
literary engineering tools that can be used by authors as a help to
creation as well as editorials as decision-support systems.  

Several scenarios are foreseen: an author using the tool to improve a
literary manuscript as well as creating new editions based on social
network reviews; a games creator using the tool to improve backstories
for characters; interactive fiction apps or websites that change story
based on user interaction and reaction and automatic adaptation of
text description of products in an online website depending on the
customer profile or the interaction of customers with it. 

The rest of the proposal is organized as follows. Next we present the
state of the art in {\em literary engineering}. Following up we will
present the long-term objectives of research, short-term objectives
for this proposal, and minimal objectives that will be achieved at the
end of the funded period. We will also present our experience in this
area, and finally our data policies and budget requests.

\section{State of the art}

In general, computational linguistics  has received a lot of
attention lately, with yearly symposiums devoted to it and many
authors advocating computational approaches to text analysis, as
opposed to purely qualitative ones \cite{roque2012towards}. The main lines
of research are concentrated around analysis and comparison of texts;
analysis tools include complex networks
\cite{1367-2630-14-4-043029,0295-5075-100-5-58002} whose extraction
from literary fiction is not trivial \cite{elson2010extracting}, but,
once done, allows a whole new set of tools for analyzing the structure
of literary works \cite{seo14:snf};  writing-style
features \cite{ASI:ASI20316} are also used for this kind of analysis
and phrase structure fragments \cite{van2012literary}, which has
recently been used to compare different kinds of literary corpus
\cite{jautze2013high}. These two papers have been the result of the
project \href{http://literaryquality.huygens.knaw.nl/}{The riddle of
  literary quality}, a institute by the Huygens institute for the
History of the Netherlands, funded by the Computational Humanities
Programme. It is indeed, interesting to see this kind of initiatives,
since they prove that measuring literaty quality computationally is
still a challenge; in fact, we intend to take this problem a bit
further by aiming to {\em improve} the quality of a literaty text
using quality measures and stochastic optimization algorithms. 

In fact, there are some works in this direction already; proactive evolution of text for its optimization has been done so far
in a very controlled environment, such as technical texts
\cite{Rascu06acontrolled,hernandez2004checking}. Doing it in a less
constrained envirohment or incorporating interactive features
has not been done so far, although nowadays is an easily available
metric, since it is very easy to measure the success of an Instagram
picture or Facebook post (the last of which is more {\em literary} in
the traditional sense, although the extensive use of hashtags by the
former could be also open to optimization). We have also experimented
by generating stories \cite{2014arXiv1403.3084G} and even whole books
\cite{Merelo201401}, but no attempt has been made to make it even
remotely literary. Content-generation tools could be combined with
content-improvement (which we call {\em literary engineering}) tools
to assist in the creation of high-quality literary (and commercial)
works, or simply increase the productivity and leave the purely
creative work to the computing engine that can do it better; the human
brain. 

Even more so, criticism can also be gauged to measure the
quality of the text it is talking about. Finally, personalization of
text, so far, has not been done to the best of our knowledge.

That is why this project will advance the state of the art in several
areas, be them algorithmic, methodological or purely technical,
providing open source tools to carry out text-improvement tasks. 

\section{Objectives}
\label{sec:obj}

The main objective is to create a tool that is able to improve the literary
quality of a written text. This objective is divided in several
sub-objectives. \begin{itemize}
\item Examine different measures of literary quality and create an
  aggregated value (or {\em fitness} that describes in a single value
  (or multiple criteria) the quality of a work.
\item Optimize text-analysis tools to be able to make a fast model of
  a written work.
\item Create an abstract phrase model that will be used to represent
  it and, eventually, optimize it
\item Design an evolutionary algorithm for optmization of literary
  texts that uses as fitness the measure described in the first bullet
  point, as representation the model described in the third bullet
  point which has been obtained in a reasonable amount of time thanks
  to the tool created in the second bullet point
\end{itemize}

A non-scientific objective will be to follow an open science
methodology during the whole duration of the project. Our team is
committed to open science, and offers as a proof former work \href{http://github.com/JJ}{developed
and described in GitHub} and the already finished project
\href{http://canube.wordpress.com}{CANUBE}, which was locally
funded. We will also draw from our own experience writing an open
source novel, \href{http://jj.github.io}{hosted at GitHub} which
allowed us to have more information than is usually available after a
novel is written and published, information that could, indeed, be
used to help with the writing process and improve the resulting text. 

This will be our minimum achievable objective\begin{enumerate}
\item Choose ten public-domain, creative commons or automatically
  generated short stories (for instance, backstories generated by our
  system MADE \cite{2014arXiv1403.3084G}.
\item Design and implement, using available open source tools (such as our Perl
  evolutionary algorithm module {\tt Algorithm::Evolutionary}
  \cite{ae09} or our node.js EA module \cite{nodeo2014}) a
  text-improvement evolutionary algorithm. 
\item Obtain a 10\% improvement of the Fog and Flesch index of said
  texts.
\end{enumerate}

In the next section we will explain the steps we will be taking,
should this proposal be funded, to
achieve this minimum objective and go beyond it. 

\section{Methodology}
\label{sec:meth}

In this section we will have a look on how the different objectives of
this proposal are going to be tackled. Next we will talk about
literary metrics or, indeed, the {\em riddle} of literary quality, a
riddle we will have to sove, at least partially, if we want to {\em
  improve} it automatically

\subsection{Literary metrics}

The relationship of Mathematics, and thus computer science with
literature was probably found by surrealists, but the first author
that was attracted to mathematics as a source of inspiration was
Raymond Queneau, a French author and translator who also became a
member of the French Mathematics Society, writing a book entitled {\em
  The fundaments of literature after David Hilberg},
\cite{queneau1976fondements}. He was mentioned as wanting to introduce
mathematic, that is, algorithmic, notions into poetry or the creation
of a novel as soon as the twenties, more or less contemporarily to
surrealism. \cite{emmer2005mathematics}. In fact, combinatorics played
a big role in his work ``Exercises in Style''
\cite{queneau2013exercises}, with 99 variations of a single story
written, by hand each time, in different styles. Mathematics is, in
this sense, more an inspiration than an actual methodology. 

And a mathematical methodology for generating or improving literature
calls for literary analytics. Measures such as Gunning ``fog'' index
\cite{gunning1969fog} or Flesch index \cite{roberts1994effects}, which
measure readability (not quality), but are useful analytics when you
want to address a text to a certain audience (for instance, patients'
families \cite{grossman1994informed}). 

In fact literary quality is a riddle since it involves syntactic and
semantic measures, as well as purely emotional ones to create an aggregated value. This
  measure will integrate measures obtained by text analysis together
  with user-generated measures (scores obtained via Amazon or Google
  Book Reviews or goodreads, {\em likes} or {\em stars} in social
  networks, and text-mining of published reviews in literary magazines
  or answers. We will include in this measure similarity measures
  obtained by analysis of classical (in general, public domain)
  works. 

So the first step in our methodology will be to delve into the puzzle
of literary quality and choose a measure, or a set of measures, that
should be optimized in order to make a text a {\em better} text. In
the process we will find whether literary quality is, in fact, a
single-objective problem, with many measures correlated with each
other, or a multimodal algorith, with multiple measures independent
with each other and needing a multiobjective optimization algorithm to
deal with them. In fact, {\em readability} measures with which we have
had certain experience are correlated, but as soon as we introduce
other measures this might not be true. At the end of this period, we
will have a set of automatic quality measures taht we will apply to
texts to perform a multi- or single-objective optimization process on
them. 

These tools will have to be applied to the text, probably preceded by
a preprocessing phase where it will be analyzed. We will talk about
this phase in the next subsection.



\section{Our experience}
\label{sec:exp}

GeNeura team (http://geneura.wordpress.com) includes a published
writer that has won literary prices in its cast, which has them
interested in this kind of things. They have been working in the
advertising industry some time in the past
\cite{merelo:ecal97,AISB97}, but also have experience in interactive
art \cite{DBLP:conf/cec/TrujilloVVG13,DBLP:conf/cec/FernandesIBRG11}.


We also have experience in performance evaluation and prediction
\cite{castillo:evostar08,hardwareevo}, as well as in the optimization of
software-defined architectures \cite{gecco08:castillo}.

Our complex systems experience arises from our early interest in
artificial life \cite{ecal93} but have lately applied complex network
analysis to co-authorship in particular areas
\cite{ec-network-2007,merelo2013complex,DBLP:journals/corr/abs-1108-0261}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Acknowledgements}
\textit{This \LaTeX template was produced by John A Stevenson, and originally published \href{http://all-geo.org/volcan01010/2013/07/grant-applications-are-hard-work-includes-latex-template}{here}.  For volcanology and scientific computing news, visit the blog at \href{http://all-geo.org/volcan01010}{http://all-geo.org/volcan01010} or follow him on Twitter \href{https://twitter.com/volcan01010}{@volcan01010}.}

\bibliographystyle{alpha}
\twocolumn[
  \begin{@twocolumnfalse}
\bibliography{literary,geneura}
\end{@twocolumnfalse}
]

\section{Data Policy}

\section{Budget}


\end{document}
